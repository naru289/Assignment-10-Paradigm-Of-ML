{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naru289/Assignment-10-Paradigm-Of-ML/blob/main/K_Means_Clustering(Customer_Segmentation)_Ungraded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement: Customer segmentation using K-Means Clustering"
      ],
      "metadata": {
        "id": "ZOWdvVNWaYxt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "surprising-uruguay"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interior-simple"
      },
      "source": [
        "The dataset chosen for this problem is the Online Retail dataset. It is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n",
        "\n",
        "Here our main goal is to cluster all the customers according to their attributes and gain more information about various customer patterns.\n",
        "\n",
        "The dataset contains 541909 records, and each record is made up of 8 fields.\n",
        "\n",
        "To know more about the dataset : (https://archive.ics.uci.edu/ml/datasets/Online+Retail)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "What is Customer Segmentaion?\n",
        "\n",
        "As the name suggests, segregating the customers to certain groups based on purchases, frequency of purchases, type of products bought, into homogeneuous groups. In any business, it is important to analyse and retain the existing customers as well as explore and attract new cutomers.\n",
        "\n",
        "To certain extend, it is found that customers retaining leads to more effort than exploring new customers. As existing customers are more likely to spend more on the products. Satisfying these customers will help to build large, and strong reliable customer base and also bolsters the repeated purchases of your products."
      ],
      "metadata": {
        "id": "tLQNMej7LLJj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "infrared-olympus"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6yE5zbTj3Tm"
      },
      "source": [
        "**Clustering** is the task of grouping together a set of objects so that the objects in the same cluster are more similar to each other than to objects in other clusters. Similarity is a measure that reflects the strength of the relationship between two data objects.\n",
        "\n",
        "In the clustering calculation, K-Means is a very popular algorithm. In this analysis, this method is used to cluster the similar data items.\n",
        "\n",
        "In Retail and E-Commerce (B2C), and more broadly in B2B, one of the key elements shaping the business strategy of a firm is understanding of customer behaviour. More specifically, understanding the customers based on different business metrics: how much they spend (revenue), how often they spend (frequency), are they new or existing customers, what are their favorite products, etc... Such understanding in turn helps direct marketing, sales, account management and product teams to support customers on a personalized level and improve the product offering.\n",
        "\n",
        "Furthermore, segmenting customers into different categories based on similar/cyclical buying pattern over a period of 1 year helps the retail shops manage their inventory better, thereby lowering costs and raising revenues by placing the orders in sync with the buying cycles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfWGmjNHdZul"
      },
      "source": [
        "Perform customer segmentation for an Online Retail dataset to segment the customers based on purchases and frequency using K-means Clustering.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run the cell to download the dataset\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "!wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/OnlineRetail.csv\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVrZPM_ICJoy"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BodsbCWT1VlC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4bF_GJdZuo"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prerequisite-knock"
      },
      "source": [
        "data = pd.read_csv('OnlineRetail.csv', encoding = 'unicode_escape')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Attributes**\n",
        "\n",
        "**InvoiceNo:** Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter ‘C’, it indicates a cancellation.\n",
        "\n",
        "**StockCode:** Product (item) code. As it is a wholesale retail store, it has unique identifier for each stock of the item.\n",
        "\n",
        "**Description:** Product (item) name. Nominal.\n",
        "\n",
        "**Quantity:** The quantities of each product (item) per transaction. Numeric.\n",
        "\n",
        "**InvoiceDate:** Invoice Date and time. Numeric, the day and time when each transaction was done by the customer.\n",
        "\n",
        "**UnitPrice:** Unit price. Numeric, Product price per unit in sterling.\n",
        "\n",
        "**CustomerID:** Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "\n",
        "**Country:** Country name. Nominal, the name of the country where each customer resides."
      ],
      "metadata": {
        "id": "U3f-LiycrWdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "nf5cdYO2j57M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "Srt-nkmokEkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data description\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "2nst_6LPkISU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Pre-processing"
      ],
      "metadata": {
        "id": "rzyv_8csjuuO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQrT5tx3dZuq"
      },
      "source": [
        "Explore the dataset by performing the following operations:\n",
        "\n",
        "* There is a lot of redundant data. check for duplicate entries from the data and remove from the data. \n",
        "\n",
        "* Most Invoices appear as normal transactions with positive quantity and prices, but there are some prefixed with \"C\" or \"A\" which denote different transaction types. Invoice starting with C represents cancelled order and A represents the Adjusted. Check the negative values in Quantity column for all cancelled orders\n",
        "\n",
        "* Handle the null values by dropping or filling with appropriate mean\n",
        "\n",
        "\n",
        "* Create a `DayOfWeek` column using `InvoiceDate`, using `pd.to_datetime()`\n",
        "\n",
        "**Note:** We perform all the above operations using a function "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# original dataframe for backup\n",
        "data_orig = data"
      ],
      "metadata": {
        "id": "OP3uZxL_aYG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for the cancelled orders data\n",
        "data[data.InvoiceNo.str[0] == 'C']"
      ],
      "metadata": {
        "id": "Pg5t9-2im6vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the cancelled orders\n",
        "len(data[data.InvoiceNo.str[0] == 'C']), len(data[data.Quantity < 1 ])"
      ],
      "metadata": {
        "id": "rTLi2CSnaYL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the null values\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "hAOmz5fGnWih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform all the pre-processing steps mentioned above\n",
        "def pre_processing(df):\n",
        "\n",
        "    # Drop the duplicates from the data\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Remove the cancelled orders from the data\n",
        "    df = df[~ (df.InvoiceNo.str[0] == 'C')]\n",
        "\n",
        "    # Drop Null values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Converting 'InvoiceDate' valuess in to pandas datatime format \n",
        "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'].values)\n",
        "\n",
        "    df['DayOfWeek'] = [i.dayofweek for i in df['InvoiceDate']]\n",
        "    df['MonthName'] = [i.month_name() for i in df['InvoiceDate']]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "cnsYacjonbrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the above pre-processing function by passing the dataframe\n",
        "data  = pre_processing(data_orig)"
      ],
      "metadata": {
        "id": "LuC2VjQIqBvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "sIFG6S29qTG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "Pqd57dy5qMVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "graphic-vampire"
      },
      "source": [
        "### Understanding new insights from the data (Exploratory Data Analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "furnished-station"
      },
      "source": [
        "1.  Are there any free items in the data? How many are there?\n",
        "\n",
        "2.  Find the number of transactions per country and visualize using an appropriate plot\n",
        "\n",
        "3.  What is the ratio of customers who are repeat purchasers vs single-time purchasers? Visualize the plot.\n",
        "\n",
        "4. Find the top 10 customers who bought the most no.of items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "united-memorial"
      },
      "source": [
        "#### 1. Are there any free items in the data ? How many are there ?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.UnitPrice == 0].count()"
      ],
      "metadata": {
        "id": "xQTjG1BNqyOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "north-power"
      },
      "source": [
        "#### 2. Find the number of transactions per country and visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prescribed-speaking"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.barh(data.Country.value_counts().index, data.Country.value_counts())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "popular-anthropology"
      },
      "source": [
        "#### 3. What is the ratio of customers who are repeat purchasers vs single-time purchasers? Visualize the plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "portuguese-secretariat"
      },
      "source": [
        "MostRepeat = data.groupby('CustomerID')['InvoiceNo'].nunique().sort_values(ascending=False)\n",
        "rep = MostRepeat[MostRepeat > 1].values\n",
        "nrep = MostRepeat[MostRepeat == 1].values\n",
        "ser = pd.Series([len(rep)/ len(MostRepeat),len(nrep)/len(MostRepeat)], index=['Repeat Customers','One-time Customers'])\n",
        "ser.plot(kind='pie', autopct='%.2f%%').set(ylabel='')\n",
        "plt.suptitle('Top Repeat Customers', fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "straight-doctor"
      },
      "source": [
        "#### 4. Find the top 10 customers who bought the most no.of items."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['CustomerID'] = data['CustomerID'].astype(int)"
      ],
      "metadata": {
        "id": "8HJd4wN9K24v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "municipal-blair"
      },
      "source": [
        "Top10Customers = data.groupby('CustomerID').agg({\"Quantity\":\"sum\"}).sort_values('Quantity', ascending=False).iloc[:10]\n",
        "print(Top10Customers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "royal-chancellor"
      },
      "source": [
        "### Feature Engineering and Transformation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dietary-willow"
      },
      "source": [
        "#### Create new features to uncover better insights and drop the unwanted columns\n",
        "\n",
        "* Create a new column which represents Total amount/Revenue per transaction spent by each customer. We ge this by using following formula:  **Quantity * UnitPrice**\n",
        "\n",
        "* Customer IDs are seen to be repeated. Maintain unique customer IDs by grouping and summing up all possible observations per customer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will check the `total_amount` spent by each customer"
      ],
      "metadata": {
        "id": "XmsU1axX4ceH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Total_Amount'] = data['Quantity'] * data['UnitPrice']"
      ],
      "metadata": {
        "id": "eATrn7lB30Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "QkPqxn5lKO47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before going further, let us understand how are we going to analyse this dataset. There are many ways to analyse this dataset, but we will be seeing RFM analysis. This analysis has been adopted and put into practise since long time ago. It plays a vital role in marketing effort. The three main variables in this analysis:\n",
        "\n",
        "**R (recency)** : It stores the number of days the customer has done his last purchase with respect to last date in the dataset. It is just to find the last a particular customer has purchaced from the store.\n",
        "\n",
        "**F (frequency)**: It is the number of times each customer has made a purchase by counting unique innovice dates each customer was seen making a purchase.\n",
        "\n",
        "**M(Monetary):** It is the total amount spent by each customer."
      ],
      "metadata": {
        "id": "cZJ6tnlXWFUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s calculate RFM values.\n",
        "\n",
        "The easiest is to calcualte the M-monetary value. We will be using the Total_Amount column that we have created before."
      ],
      "metadata": {
        "id": "bait2fkPWO6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = data.groupby('CustomerID')['Total_Amount'].sum()\n",
        "m = pd.DataFrame(m).reset_index()\n",
        "m.head()"
      ],
      "metadata": {
        "id": "i24c7x0eV8md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the first few rows of the new dataframe, we can see that we calculated the monetary value for each customer!"
      ],
      "metadata": {
        "id": "oY8q5RXbWWdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s calculate the number of times each customer purchased from the store. We will be using the CustomerID and InvoiceDate columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "T1BRkW2iWca3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = data.groupby('CustomerID')['InvoiceNo'].count()\n",
        "f = f.reset_index()\n",
        "f.columns = ['CustomerID','Frequency']\n",
        "f.head()"
      ],
      "metadata": {
        "id": "TRjYRMHGWXPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were able to calculate the total number of times each customer purchased from the store."
      ],
      "metadata": {
        "id": "CLyJbtFSWlGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, Let’s calculate R-receny value for each customer.\n",
        "\n",
        "\n",
        "First, we need to find the when was the last purchase done in the data set.\n",
        "\n"
      ],
      "metadata": {
        "id": "kkAXPTZoWnvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_day = max(data['InvoiceDate'])"
      ],
      "metadata": {
        "id": "4LefuuwdWg5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out the last date of purchase of each customer\n",
        "\n"
      ],
      "metadata": {
        "id": "aE_fVkHHW3tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['difference'] = last_day - data['InvoiceDate']\n",
        "data.head()"
      ],
      "metadata": {
        "id": "OmH7DqgyW1ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need just the number of days but not the time and days attached to it just the integer. So that, it is easier to groupby later on based on each customer."
      ],
      "metadata": {
        "id": "MTrchSEkXDJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can have a seperate function to give the integer number.\n",
        "\n"
      ],
      "metadata": {
        "id": "TCaFYNlVXGwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_days(x):\n",
        "    y = str(x).split()[0]\n",
        "    return int(y)\n",
        "data['difference'] = data['difference'].apply(get_days)"
      ],
      "metadata": {
        "id": "CW-loND1W56k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "_bp7oZNaXK_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can groupby each customer by using CustomerId and difference column."
      ],
      "metadata": {
        "id": "sIUrvg0QXQFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = data.groupby('CustomerID')['difference'].min()\n",
        "r = r.reset_index()\n",
        "r.columns = ['CustomerID','Recency']\n",
        "r.head()"
      ],
      "metadata": {
        "id": "7S4x4LwfXMMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have created all three seperate dataframes for Recency (r), frequency (f), monetary (m). Let’s group these dataframes."
      ],
      "metadata": {
        "id": "SH1yzZBsXZd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_df = pd.merge(m, f, on = 'CustomerID',how = 'inner')\n",
        "RFM_df = pd.merge(grouped_df, r, on ='CustomerID', how = 'inner')\n",
        "RFM_df.columns = ['CustomerID','Monetary','Frequency','Recency']"
      ],
      "metadata": {
        "id": "4t4V1LVJXZr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are doing inner join to group up 3 dataframes.\n",
        "\n",
        "As K-means clustering access every data point to form a cluster, having outliers can affect in process of detecting clusters so first lets drop the outliers so that we can get better clusters later on.\n",
        "\n"
      ],
      "metadata": {
        "id": "jpClPLQ_Xj-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s look at the box plot of each column.\n",
        "\n"
      ],
      "metadata": {
        "id": "T_cQPY3YXnTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(16, 8))\n",
        "sns.boxplot(ax=axes[0], x=RFM_df[\"Monetary\"]);\n",
        "sns.boxplot(ax=axes[1], x=RFM_df[\"Frequency\"]);\n",
        "sns.boxplot(ax=axes[2], x=RFM_df[\"Recency\"]);"
      ],
      "metadata": {
        "id": "ukz8cy1cU9SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As each variable has outliers lets drop them. Refer to the following [link](https://kanoki.org/2020/04/23/how-to-remove-outliers-in-python/) on how to remove outliers\n",
        "\n"
      ],
      "metadata": {
        "id": "-RpFbwrjX9GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_vars = ['Monetary','Recency','Frequency']\n",
        "for column in outlier_vars:\n",
        "    \n",
        "    lower_quartile = RFM_df[column].quantile(0.25)\n",
        "    upper_quartile = RFM_df[column].quantile(0.75)\n",
        "    iqr = upper_quartile - lower_quartile\n",
        "    iqr_extended = iqr * 1.5\n",
        "    min_border = lower_quartile - iqr_extended\n",
        "    max_border = upper_quartile + iqr_extended\n",
        "    \n",
        "    outliers = RFM_df[(RFM_df[column] < min_border) | (RFM_df[column] > max_border)].index\n",
        "    print(f\"{len(outliers)} outliers detected in column {column}\")\n",
        "    \n",
        "    RFM_df.drop(outliers, inplace = True)"
      ],
      "metadata": {
        "id": "I80WIPvlX-no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Scaling\n",
        "\n",
        "Now we need to standardise the data, as there are larger vlaues that can dominate from defining clusters.\n",
        "\n",
        "As clustering algorithm is based on distance between the data points, we need to scale the data to follow a normal distribution of mean 0 and standard deviation of 1."
      ],
      "metadata": {
        "id": "J8TvHzG7YX6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df = RFM_df[['Monetary','Frequency','Recency']]\n",
        "scale_standardisation = StandardScaler()\n",
        "rfm_df_scaled = scale_standardisation.fit_transform(scaled_df)\n",
        "rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\n",
        "rfm_df_scaled.columns = ['monetary','frequency','recency']"
      ],
      "metadata": {
        "id": "w21eveoSYRq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_df_scaled.head()"
      ],
      "metadata": {
        "id": "WMfY2wIKXkRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see how the k-means algorithm works."
      ],
      "metadata": {
        "id": "WhanOBhpbREg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JtDbb51pjTU"
      },
      "source": [
        "#### Working of k-means algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EYiGtnnpjTU"
      },
      "source": [
        "It starts by placing the centroids randomly (e.g., by picking k instances at random and using their locations as centroids). Then label the instances and update the centroids, then again label the instances and update the centroids, and so on until the centroids stop moving. The algorithm converges in a finite number of steps.\n",
        "\n",
        "In order to update the label of instances, k-means computes the distance of each instance from every cluster and assigns the one which is closest to them. Also, each centroid  is updated to the mean of all instances assigned to that cluster as shown in the figure below.\n",
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://cdn.iisc.talentsprint.com/CDS/Images/Kmeans_cluster_update.JPG\" width=650/>\n",
        "</center>\n",
        "\n",
        "The algorithm halts creating and optimizing clusters when either:\n",
        "\n",
        "* The centroids have stabilized — there is no change in their values because the clustering has been successful.\n",
        "* The defined number of iterations has been achieved."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Till now we don't know how many clusters the dataset contains or it is hard to identify even with visualization."
      ],
      "metadata": {
        "id": "qchDd5ADYlQz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn1qD44PI0H_"
      },
      "source": [
        "#### Apply k-means algorithm to identify a specific number of clusters\n",
        "\n",
        "\n",
        "* Fit the k-means model\n",
        "\n",
        "* Extract and store the cluster centroids\n",
        "\n",
        "Below are the parameters for k-means, which are helpful\n",
        "\n",
        "**n_clusters** is no. of clusters specified\n",
        "\n",
        "**k-means++** is a random initialization method for centroids to avoid random initialisation trap\n",
        "\n",
        "**max_iter** is max no of iterations defined when k-means is running\n",
        "\n",
        "**n_init** is no. of times k-means will run with different initial centroids\n",
        "\n",
        "**Note:** Refer to the following [link](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) on  k-means from sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h64gqdQkaVZB"
      },
      "source": [
        "#### Find the optimal number of clusters (K) by using the Elbow method.\n",
        "\n",
        "Here is a technique called **\"Elbow Method\"** that helps to find the approipriate clusters for building the clustering model.  \n",
        "\n",
        "Elbow method gives us an idea on what a good **k** number of clusters would be based on the **sum of squared distance (SSE) or within cluster sum of errors (wcss)** between data points and their assigned clusters’ centroids. We pick **k** at the spot where SSE starts to flatten out and forming an elbow. In scikit learn, we calculate this SSE using `KMeans.inertia_` method. The KMeans class runs the algorithm n_init times and keeps the model with the lowest inertia.\n",
        "\n",
        "The inertia is not a good performance metric when trying to choose $k$ because it keeps getting lower as we increase $k$. Indeed, the more clusters there are, the closer each instance will be to its closest centroid, and therefore the lower the inertia will be. \n",
        "\n",
        "Let’s plot the inertia as a function of $k$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot inertia by varying number of clusters\n",
        "clusters = np.arange(1,10)\n",
        "inertia = []\n",
        "for c in clusters:\n",
        "    kmeans = KMeans(n_clusters = c, random_state=1)\n",
        "    kmeans.fit(rfm_df_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "plt.plot(clusters, inertia, marker= '.')\n",
        "plt.title('Inertia Plot')\n",
        "plt.xlabel(\"$k$\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nWhys0SffO7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p28qpRzZpjTX"
      },
      "source": [
        "From the above plot we can see, the inertia drops very quickly as we increase $k$ up to 3, but then it decreases much more slowly as we keep increasing $k$. This curve has roughly the shape of an arm, and there is an **“elbow”** at $k = 3$. So, if we did not know better, $3$ would be a good choice.\n",
        "\n",
        "This technique for choosing the best value for the number of clusters is rather coarse. A **more precise approach** but also more computationally expensive is to use the **silhouette score**, which is the mean silhouette coefficient over all the instances. \n",
        "\n",
        "An instance’s silhouette coefficient is given by $$Sil(x_1) = \\frac{(b – a)}{max(a, b)}$$ where, \n",
        "\n",
        "$a$ is the mean distance to the other instances in the same cluster (i.e., the mean intra-cluster distance), and \n",
        "\n",
        "$b$ is the mean nearest-cluster distance (i.e., the mean distance to the instances of the next closest cluster, defined as the one that minimizes $b$, excluding the instance’s own cluster) as shown in the figure below. \n",
        "\n",
        "<center>\n",
        "<img src=\"https://cdn.iisc.talentsprint.com/CDS/Images/Silhouette_coefficient.png\" width= 500 px/>\n",
        "</center>\n",
        "\n",
        "The silhouette coefficient can vary between $–1$ and $+1$ as follows: \n",
        "\n",
        "* close to $+1$ means that the instance is well inside its own cluster and far from other clusters, \n",
        "* close to $0$ means that it is close to a cluster boundary, and  \n",
        "* close to $–1$ means that the instance may have been assigned to the wrong cluster. \n",
        "\n",
        "To compute the silhouette score, we can use Scikit-Learn’s `silhouette_score()` function refer to the following [link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html), giving it all the instances in the dataset and the labels they were assigned:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Silhouette score plot\n",
        "clusters = np.arange(2,10)\n",
        "sil_score = []\n",
        "for c in clusters:\n",
        "    kmeans = KMeans(n_clusters = c, random_state=1)\n",
        "    kmeans.fit(rfm_df_scaled)\n",
        "    sil_coeff = silhouette_score(rfm_df_scaled, kmeans.labels_)\n",
        "    sil_score.append(sil_coeff)\n",
        "    print(f\"cluster = {c}\\t-->{sil_coeff}\")\n",
        "plt.plot(clusters, sil_score, marker= '.')\n",
        "plt.title('Silhouette score plot')\n",
        "plt.xlabel(\"$k$\")\n",
        "plt.ylabel(\"Silhouette score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FNZW7ocUhSvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa36f_E_pjTY"
      },
      "source": [
        "As we can see, the above visualization is much richer than the previous one: although it shows that $k = 2$ is a good choice, it also underlines the fact that $k = 3$ is quite good as well and much better than $k = 4$ or $5$. This was not visible when comparing inertias. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, from the above plot we will choose the number of clusters or customer groups to be 3."
      ],
      "metadata": {
        "id": "GSdworgNZ7ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters = 3)\n",
        "kmeans.fit_predict(rfm_df_scaled)"
      ],
      "metadata": {
        "id": "xzuHUdjTZ6e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To understand the behavior of the customers from each cluster print the respective centroid point values\n",
        "cluster_centers = pd.DataFrame(data = kmeans.cluster_centers_, columns = [rfm_df_scaled.columns])\n",
        "cluster_centers"
      ],
      "metadata": {
        "id": "M8FEc6aN9XI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FarGC20zgjHj"
      },
      "source": [
        "### Analyze the clusters\n",
        "\n",
        "- Visualize the clusters with different colors using the predicted cluster centers.\n",
        "\n",
        "  **Hint:** [3D plot](https://matplotlib.org/stable/gallery/mplot3d/scatter3d.html\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = kmeans.labels_\n",
        "RFM = rfm_df_scaled \n",
        "RFM['clusters'] = clusters\n",
        "centroids = kmeans.cluster_centers_\n",
        "fig = plt.figure(figsize=(20,12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(RFM[\"monetary\"][RFM.clusters == 0], RFM[\"frequency\"][RFM.clusters == 0], RFM[\"recency\"][RFM.clusters == 0], c='blue', s=30)\n",
        "ax.scatter(RFM[\"monetary\"][RFM.clusters == 1], RFM[\"frequency\"][RFM.clusters == 1], RFM[\"recency\"][RFM.clusters == 1], c='red', s=30)\n",
        "ax.scatter(RFM[\"monetary\"][RFM.clusters == 2], RFM[\"frequency\"][RFM.clusters == 2], RFM[\"recency\"][RFM.clusters == 2], c='yellow', s=30)\n",
        "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], s = 1100, c = 'k',  marker=\"*\")\n",
        "\n",
        "ax.view_init(30, 200)\n",
        "plt.xlabel(\"Monetary\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "ax.set_zlabel('Recency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sOx5FuTOuFAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plot, we can see that the centroids after applying the k-means in black star"
      ],
      "metadata": {
        "id": "FAwRWxeb7T8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a new column in the RMF dataframe refering to the assigned clusters\n",
        "RFM.head()"
      ],
      "metadata": {
        "id": "vN9a5RidYR8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s look at the analytics of RFM dataframe."
      ],
      "metadata": {
        "id": "c-ni64ISaLzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RFM_df['Clusters'] = kmeans.labels_\n",
        "\n",
        "analysis = RFM_df.groupby('Clusters').agg({\n",
        "    'Recency':['mean','max','min'],\n",
        "    'Frequency':['mean','max','min'],\n",
        "    'Monetary':['mean','max','min']})"
      ],
      "metadata": {
        "id": "SZspEUiFaMIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(analysis)"
      ],
      "metadata": {
        "id": "45RS2r7Z8sc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Analysis Below:\n",
        "\n",
        "### First customer cluster: Frequent and minimum amount spent by the customer\n",
        "\n",
        "### Second customers cluster: Recently visited the store with maximum frequency and spending the amount by customer\n",
        "\n",
        "### Third Customers cluster: The last transaction was sometime back and minimum amount spent by the customer, \n",
        "#                             Average number of purchases by the customer"
      ],
      "metadata": {
        "id": "20927f2T8ti2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}